schema: study/v1
study_name: diffusion_10k
out_dir: "runs/"
seed: 1077
metric: val/fid

_experiment:
  name: "E6-sampler-parity-linear-ddim-50nfe"

device: null     # auto
deterministic: true
clean_run: false

data:
  dataset: "cifar10"
  subset: null      # full train
  batch_size: 4
  num_workers: 2
  shuffle: true

model:
  name: "unet_cifar32"
  # same model as E1/E2/E5

ema:
  enabled: true
  decay: 0.9999

diffusion:
  enabled: true
  beta_schedule: "linear"   # E6: linear schedule (parity vs cosine)

optim:
  optimizer: adam
  lr: 1.0e-4

train:
  total_steps: 10000        # same 10k baseline as E1/E2/E5
  grad_clip: 1.0
  amp: true                 # follow your current default


# evaluations cfg:
eval:
  quick: false              # leave grids / FID enabled

  grid:
    enabled: true
    every: 1000
    sampler: ddim           # small grids via DDIM (your current pattern)
    nfe: 20
    n_samples: 36
    save_images: true

  kid:
    enabled: false
    every: 4000
    n_samples: 1024
    repeats: 3
    sampler: ddim
    nfe: 20

  fid_milestone:
    enabled: false
    every: 20000
    run_if_kid_improved_pct: 3.0
    sampler: ddpm
    nfe: 50
    n_samples: 5000
    fid_stats: "stats/cifar10_inception_train.npz"

  final:
    enabled: true
    at_end: true
    sampler: ddim          # <-- key change: DDIM final sampler
    nfe: 50
    n_samples: 10000
    fid_stats: "stats/cifar10_inception_train.npz"

variants: []

logging:
  enable: true
  backends: ["tensorboard","wandb"]
  log_every_n_steps: 100

  wandb:
    mode: online
    project: noise_sched
    run_name: "E6-linear-ddim-10k"
    tags: ["E6", "sampler-parity", "linear", "ddim", "10k"]
    notes: "E6: sampler parity check, linear Î², DDIM sampler @ NFE=50."

  tensorboard:
    flush_secs: 10